{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import datetime as dt\n",
    "import imp\n",
    "import json\n",
    "import random\n",
    "from itertools import combinations_with_replacement\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from math import ceil\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from game_lists_site.models import (\n",
    "    BenchmarkUserCBR,\n",
    "    BenchmarkUserMBCF,\n",
    "    BenchmarkUserSimilarity,\n",
    "    Game,\n",
    "    System,\n",
    "    User,\n",
    "    UserGame,\n",
    "    GameStats,\n",
    "    db,\n",
    "    user_data_dir,\n",
    ")\n",
    "from game_lists_site.utils.utils import (\n",
    "    days_delta,\n",
    "    get_cbr_for_game,\n",
    "    normalize_dict,\n",
    "    get_game_stats,\n",
    ")\n",
    "\n",
    "db.rollback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<User: 76561198125290350>, <User: 76561198094109207>, <User: 76561198026681120>, <User: 76561198091812571>, <User: 76561198083927294>, <User: 76561198067514875>, <User: 76561198394079733>]\n"
     ]
    }
   ],
   "source": [
    "# get users\n",
    "users = []\n",
    "for user in User.select(User.id, User.username):\n",
    "    game_with_score_count = (\n",
    "        UserGame.select(UserGame.id)\n",
    "        .where((UserGame.user == user) & (UserGame.score > 0))\n",
    "        .count()\n",
    "    )\n",
    "    if game_with_score_count > 1:\n",
    "        users.append(user)\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_playtimes(min_player_count, normalize, zscore_norm):\n",
    "    games = [\n",
    "        gs.game\n",
    "        for gs in GameStats.select(GameStats.game).where(\n",
    "            GameStats.player_count >= min_player_count\n",
    "        )\n",
    "    ]\n",
    "    users_games = (\n",
    "        UserGame.select(UserGame.playtime, UserGame.user)\n",
    "        .where(UserGame.playtime > 0))\n",
    "    result = {}\n",
    "    for game in games:\n",
    "        users_game = users_games.where(UserGame.game == game)\n",
    "        playtimes = [user_game.playtime for user_game in users_game]\n",
    "        if normalize:\n",
    "            if zscore_norm:\n",
    "                playtimes = stats.zscore(playtimes)\n",
    "            else:\n",
    "                playtimes = preprocessing.normalize([playtimes])[0]\n",
    "        result[game.id] = {\n",
    "            ug.user.id: playtime for ug, playtime in zip(users_game, playtimes)\n",
    "        }\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbr for user\n",
    "def reset_benchmark_cbr_for_user(users):\n",
    "    #users = User.select().where(User.last_benchmark_cbr_update_time != None)\n",
    "    system, _ = System.get_or_create(key=\"GameCBR\")\n",
    "    system.date_time_value = None\n",
    "    system.save()\n",
    "    for user in users:\n",
    "        user.last_benchmark_cbr_update_time = None\n",
    "        user.save()\n",
    "\n",
    "\n",
    "def check_result(result_games: list, check_games: list):\n",
    "    check_game_len = len(check_games)\n",
    "    return (\n",
    "        len(set(result_games[: len(check_games)]).intersection(check_games))\n",
    "        / check_game_len\n",
    "    )\n",
    "\n",
    "\n",
    "def get_benchmark_cbr_for_user(\n",
    "    user, result_count=-1, min_player_count=24, cbr_for_game_result_count=2\n",
    "):\n",
    "    if (\n",
    "        not user.last_benchmark_cbr_update_time\n",
    "        or days_delta(user.last_benchmark_cbr_update_time) >= 7\n",
    "    ):\n",
    "        played_user_games = UserGame.select(\n",
    "            UserGame.game, UserGame.last_played, UserGame.score\n",
    "        ).where((UserGame.user == user) & (UserGame.playtime > 0))\n",
    "        last_played = np.quantile([ug.last_played for ug in played_user_games], 0.8)\n",
    "        played_user_games = played_user_games.where(UserGame.last_played < last_played)\n",
    "        played_games = [ug.game for ug in played_user_games]\n",
    "        user_games_with_score = played_user_games.where(UserGame.score > 0)\n",
    "        games_with_score = [ug.game for ug in user_games_with_score]\n",
    "        result = {}\n",
    "        for user_game, game_cbr_result in zip(\n",
    "            user_games_with_score,\n",
    "            [\n",
    "                get_cbr_for_game(g, cbr_for_game_result_count, min_player_count)\n",
    "                for g in games_with_score\n",
    "            ],\n",
    "        ):\n",
    "            if game_cbr_result:\n",
    "                for sim_game in game_cbr_result:\n",
    "                    if sim_game not in played_games and sim_game.rating >= 7:\n",
    "                        if sim_game.id not in result:\n",
    "                            result[sim_game.id] = (\n",
    "                                user_game.score * game_cbr_result[sim_game]\n",
    "                            )\n",
    "                        else:\n",
    "                            result[sim_game.id] += (\n",
    "                                user_game.score * game_cbr_result[sim_game]\n",
    "                            )\n",
    "        benchmark_user_cbr, _ = BenchmarkUserCBR.get_or_create(user=user)\n",
    "        benchmark_user_cbr.data = json.dumps(\n",
    "            normalize_dict(\n",
    "                dict(sorted(result.items(), key=lambda x: x[1], reverse=True))\n",
    "            )\n",
    "        )\n",
    "        benchmark_user_cbr.save()\n",
    "        benchmark_user_cbr.save()\n",
    "        user.last_benchmark_cbr_update_time = dt.datetime.now()\n",
    "        user.save()\n",
    "    data = {\n",
    "        Game.get_by_id(game_id): value\n",
    "        for game_id, value in json.loads(\n",
    "            BenchmarkUserCBR.get_or_none(BenchmarkUserCBR.user == user).data\n",
    "        ).items()\n",
    "    }\n",
    "    if result_count != -1:\n",
    "        return dict(list(data.items())[:result_count])\n",
    "    else:\n",
    "        return dict(list(data.items()))\n",
    "\n",
    "\n",
    "def train_cbr_for_user(users, try_count = 100):\n",
    "    best_accuracy = 0\n",
    "    best_min_player_count = 1\n",
    "    best_cbr_for_game_result_count = 1\n",
    "    file = Path(\"cbr.csv\")\n",
    "    if file.exists():\n",
    "        df = pd.read_csv(file)\n",
    "        data = df.values.tolist()\n",
    "    else:\n",
    "        data = []\n",
    "    print(data)\n",
    "    def check(min_player_count, cbr_for_game_result_count):\n",
    "        sub_data = [el[:2] for el in data]\n",
    "        if [float(min_player_count), float(cbr_for_game_result_count)] in sub_data:\n",
    "            return True\n",
    "    for i in range(try_count):\n",
    "        reset_benchmark_cbr_for_user(users)\n",
    "        min_player_count = random.randint(1, 50)\n",
    "        cbr_for_game_result_count = random.randint(1, 50)\n",
    "        if check(min_player_count, cbr_for_game_result_count):\n",
    "            print(\"already exist\")\n",
    "            continue\n",
    "        cbr_accuracy = []\n",
    "        for user in users:\n",
    "            played_user_games = UserGame.select(\n",
    "                UserGame.game, UserGame.last_played\n",
    "            ).where((UserGame.user == user) & (UserGame.playtime > 0))\n",
    "            last_played = np.quantile([ug.last_played for ug in played_user_games], 0.8)\n",
    "            input_user_games = played_user_games.where(\n",
    "                UserGame.last_played < last_played\n",
    "            )\n",
    "            check_user_games = played_user_games.where(\n",
    "                UserGame.last_played >= last_played\n",
    "            )\n",
    "            played_games = [ug.game for ug in input_user_games]\n",
    "            check_games = [ug.game for ug in check_user_games]\n",
    "            cbr_result = get_benchmark_cbr_for_user(\n",
    "                user, -1, min_player_count, cbr_for_game_result_count\n",
    "            )\n",
    "            cbr_accuracy.append(check_result(list(cbr_result.keys()), check_games))\n",
    "        current_accuracy = np.mean(cbr_accuracy)\n",
    "        data.append([min_player_count, cbr_for_game_result_count, current_accuracy])\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(file, index=False)\n",
    "        print(\"current\", current_accuracy, min_player_count, cbr_for_game_result_count)\n",
    "        if  best_accuracy < current_accuracy:\n",
    "            best_accuracy = current_accuracy\n",
    "            best_min_player_count = min_player_count\n",
    "            best_cbr_for_game_result_count = cbr_for_game_result_count\n",
    "        print(\"best\", best_accuracy, best_min_player_count, best_cbr_for_game_result_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_cbr_for_user(users, 0.099)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mbcf for user\n",
    "\n",
    "def reset_benchmark_mbcf_for_user(users):\n",
    "    systems = [\n",
    "        System.get_or_none(System.key == \"BenchmarkUserMBCF\"),\n",
    "        System.get_or_none(System.key == \"NormalizedPlaytime\"),\n",
    "        System.get_or_none(System.key == \"BenchmarkUserSimilarity\"),\n",
    "    ]\n",
    "    for system in systems:\n",
    "        if system:\n",
    "            system.date_time_value = None\n",
    "            system.save()\n",
    "    for user in users:\n",
    "        user.last_benchmark_mbcf_update_time = None\n",
    "        user.save()\n",
    "\n",
    "\n",
    "def get_similar_users(\n",
    "    user,\n",
    "    normalized_playtimes,\n",
    "    max_count=-1,\n",
    "    corrcoef=False,\n",
    "):\n",
    "    system, _ = System.get_or_create(key=\"BenchmarkUserSimilarity\")\n",
    "    if not system.date_time_value or days_delta(system.date_time_value) >= 7:\n",
    "        games = list(normalized_playtimes.keys())\n",
    "        users = {}\n",
    "        for game in normalized_playtimes.keys():\n",
    "            for u in normalized_playtimes[game].keys():\n",
    "                if u in users:\n",
    "                    users[u] += 1\n",
    "                else:\n",
    "                    users[u] = 1\n",
    "        users = [u for u, game_count in users.items() if game_count >= 10]\n",
    "        game_vecs = []\n",
    "        for game in games:\n",
    "            game_vec = []\n",
    "            for u in users:\n",
    "                value = normalized_playtimes[game].get(u)\n",
    "                game_vec.append(value if value else 0)\n",
    "            game_vecs.append(game_vec)\n",
    "        game_vecs = np.array(game_vecs, dtype=np.float32)\n",
    "        user_vecs = np.flip(np.rot90(game_vecs), 0)\n",
    "        if corrcoef:\n",
    "            user_vecs = np.corrcoef(user_vecs)\n",
    "        else:\n",
    "            user_vecs = cosine_similarity(user_vecs)\n",
    "        users_sim = {}\n",
    "        BenchmarkUserSimilarity.delete().execute()\n",
    "        for u_a, user_vec in zip(users, user_vecs):\n",
    "            result = []\n",
    "            for u_b, value in zip(users, user_vec):\n",
    "                result.append((u_b, float(value)))\n",
    "            BenchmarkUserSimilarity.create(\n",
    "                user=User.get_by_id(u_a),\n",
    "                data=dict(sorted(result, key=lambda x: x[1], reverse=True)),\n",
    "            )\n",
    "        system.date_time_value = dt.datetime.now()\n",
    "        system.save()\n",
    "    user_similarity = BenchmarkUserSimilarity.get_or_none(\n",
    "        BenchmarkUserSimilarity.user == user\n",
    "    )\n",
    "    if user_similarity:\n",
    "        if max_count == -1:\n",
    "            return user_similarity.data\n",
    "        else:\n",
    "            return dict(list(user_similarity.data.items())[1 : max_count + 1])\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def get_benchmark_mbcf_for_user(\n",
    "    user,\n",
    "    max_count=-1,\n",
    "    min_player_count=39,\n",
    "    sim_user_count=36,\n",
    "    zscore_norm=False,\n",
    "    corrcoef=True,\n",
    "):\n",
    "    if (\n",
    "        not user.last_benchmark_mbcf_update_time\n",
    "        or days_delta(user.last_benchmark_mbcf_update_time) >= 7\n",
    "    ):\n",
    "        normalized_playtimes = get_normalized_playtimes(\n",
    "            min_player_count, True, zscore_norm\n",
    "        )\n",
    "        users_sim = get_similar_users(\n",
    "            user, normalized_playtimes, sim_user_count, corrcoef\n",
    "        )\n",
    "        played_user_games = UserGame.select(\n",
    "            UserGame.game, UserGame.last_played, UserGame.score\n",
    "        ).where((UserGame.user == user) & (UserGame.playtime > 0))\n",
    "        last_played = np.quantile([ug.last_played for ug in played_user_games], 0.8)\n",
    "        played_user_games = played_user_games.where(UserGame.last_played < last_played)\n",
    "        played_games = [ug.game for ug in played_user_games]\n",
    "        played_game_ids = [g.id for g in played_games]\n",
    "        result = {}\n",
    "        for game_id in normalized_playtimes.keys():\n",
    "            if game_id not in played_game_ids:\n",
    "                for user_id, value in users_sim.items():\n",
    "                    pt = normalized_playtimes[game_id].get(int(user_id))\n",
    "                    if pt:\n",
    "                        if game_id in result:\n",
    "                            result[game_id] += pt * value\n",
    "                        else:\n",
    "                            result[game_id] = pt * value\n",
    "        user_mbcf, _ = BenchmarkUserMBCF.get_or_create(\n",
    "            user=user,\n",
    "        )\n",
    "        user_mbcf.data = dict(sorted(result.items(), key=lambda x: x[1], reverse=True))\n",
    "        user_mbcf.save()\n",
    "        user.last_benchmark_mbcf_update_time = dt.datetime.now()\n",
    "        user.save()\n",
    "    user_mbcf = BenchmarkUserMBCF.get_or_none(BenchmarkUserMBCF.user == user)\n",
    "    if user_mbcf:\n",
    "        data = {\n",
    "            Game.get_by_id(int(key)): value for key, value in user_mbcf.data.items()\n",
    "        }\n",
    "        if max_count == -1:\n",
    "            return data\n",
    "        else:\n",
    "            return dict(list(data.items())[:max_count])\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "\n",
    "# reset_benchmark_mbcf_for_user(users)\n",
    "# for user in users:\n",
    "# print(user.username, get_benchmark_mbcf_for_user(user, 10))\n",
    "\n",
    "\n",
    "def check_result(result_games: list, check_games: list):\n",
    "    check_game_len = len(check_games)\n",
    "    return (\n",
    "        len(set(result_games[: len(check_games)]).intersection(check_games))\n",
    "        / check_game_len\n",
    "    )\n",
    "\n",
    "\n",
    "def train_mbcf_for_user(users, try_count = 100):\n",
    "    best_accuracy = 0\n",
    "    best_cbr_for_game_result = 1\n",
    "    best_min_player_count = 1\n",
    "    best_zscore_norm = False\n",
    "    best_corrcoef = False\n",
    "    file = Path(\"mbcf.csv\")\n",
    "    if file.exists():\n",
    "        df = pd.read_csv(file)\n",
    "        data = df.values.tolist()\n",
    "    else:\n",
    "        data = []\n",
    "    def check(min_player_count, sim_user_count, zscore_norm, corrcoef):\n",
    "        sub_data = [el[:4] for el in data]\n",
    "        if [min_player_count, sim_user_count, zscore_norm, corrcoef] in sub_data:\n",
    "            return True\n",
    "    for i in range(try_count):\n",
    "        try:\n",
    "            reset_benchmark_mbcf_for_user(users)\n",
    "            zscore_norm = random.choice([True, False])\n",
    "            corrcoef = random.choice([True, False])\n",
    "            min_player_count = random.randint(1, 50)\n",
    "            sim_user_count= random.randint(1, 50)\n",
    "            if check(min_player_count, sim_user_count, zscore_norm, corrcoef):\n",
    "                print(\"already exist\")\n",
    "                continue\n",
    "            mbcf_accuracy = []\n",
    "            for user in users:\n",
    "                played_user_games = UserGame.select(\n",
    "                    UserGame.game, UserGame.last_played\n",
    "                ).where((UserGame.user == user) & (UserGame.playtime > 0))\n",
    "                last_played = np.quantile(\n",
    "                    [ug.last_played for ug in played_user_games], 0.8\n",
    "                )\n",
    "                input_user_games = played_user_games.where(\n",
    "                    UserGame.last_played < last_played\n",
    "                )\n",
    "                check_user_games = played_user_games.where(\n",
    "                    UserGame.last_played >= last_played\n",
    "                )\n",
    "                played_games = [ug.game for ug in input_user_games]\n",
    "                check_games = [ug.game for ug in check_user_games]\n",
    "                mbcf_result = get_benchmark_mbcf_for_user(\n",
    "                    user, -1, min_player_count, sim_user_count, zscore_norm, corrcoef\n",
    "                )\n",
    "                mbcf_accuracy.append(check_result(list(mbcf_result.keys()), check_games))\n",
    "            current_accuracy = np.mean(mbcf_accuracy)\n",
    "            data.append([min_player_count, sim_user_count, zscore_norm, corrcoef, current_accuracy])\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(file, index=False)\n",
    "            print(\"current\", current_accuracy, min_player_count, sim_user_count, zscore_norm, corrcoef)\n",
    "            if best_accuracy < current_accuracy:\n",
    "                best_accuracy = current_accuracy\n",
    "                best_min_player_count = min_player_count\n",
    "                best_sim_user_count = sim_user_count \n",
    "                best_zscore_norm = zscore_norm\n",
    "                best_corrcoef = corrcoef\n",
    "            print(\"best\", best_accuracy, best_min_player_count, best_sim_user_count, best_zscore_norm, best_corrcoef)\n",
    "        except ValueError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_cbr_for_user(users, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_mbcf_for_user(users, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobcf for user\n",
    "def reset_benchmark_mobcf_for_user():\n",
    "    systems = [\n",
    "        System.get_or_none(System.key == \"BenchmarkUserMOBCF\"),\n",
    "        System.get_or_none(System.key == \"NormalizedPlaytime\"),\n",
    "    ]\n",
    "    for system in systems:\n",
    "        if system:\n",
    "            system.date_time_value = None\n",
    "            system.save()\n",
    "\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100):\n",
    "        super(MF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "\n",
    "    def forward(self, u, v):\n",
    "        u = self.user_emb(u)\n",
    "        v = self.item_emb(v)\n",
    "        return (u * v).sum(1)\n",
    "\n",
    "    def print(self, u, v):\n",
    "        u = self.user_emb(u)\n",
    "        v = self.item_emb(v)\n",
    "        print(\"u\", u)\n",
    "        print(\"v\", u)\n",
    "\n",
    "\n",
    "def get_benchmark_mobcf_for_user(\n",
    "    target_user: User, max_count=-1, min_player_count=38, zscore_norm=True\n",
    "):\n",
    "    system, _ = System.get_or_create(key=\"BenchmarkUserMOBCF\")\n",
    "    if not system.date_time_value or days_delta(system.date_time_value) >= 7:\n",
    "        normalized_playtimes = get_normalized_playtimes(\n",
    "            min_player_count, True, zscore_norm\n",
    "        )\n",
    "        users_games = {}\n",
    "        for game_id in normalized_playtimes.keys():\n",
    "            for user_id in normalized_playtimes[game_id].keys():\n",
    "                if user_id not in users_games:\n",
    "                    users_games[user_id] = {}\n",
    "                users_games[user_id][game_id] = normalized_playtimes[game_id][user_id]\n",
    "        users_to_delete = []\n",
    "        for user_id in users_games.keys():\n",
    "            if len(users_games[user_id]) < ceil(10 / 0.8):\n",
    "                users_to_delete.append(user_id)\n",
    "        for user_id in users_to_delete:\n",
    "            users_games.pop(user_id)\n",
    "        data = []\n",
    "        for user_id in users_games:\n",
    "            user_games = (\n",
    "                UserGame.select(UserGame.game, UserGame.last_played)\n",
    "                .join(User)\n",
    "                .where((UserGame.user.id == user_id) & (UserGame.playtime > 0))\n",
    "            )\n",
    "            last_played = np.quantile([ug.last_played for ug in user_games], 0.8)\n",
    "            played_user_games = user_games.where(UserGame.last_played < last_played)\n",
    "            for ug in played_user_games:\n",
    "                pt = users_games[user_id].get(ug.game.id)\n",
    "                if pt:\n",
    "                    data.append(\n",
    "                        {\n",
    "                            \"user_id\": user_id,\n",
    "                            \"game_id\": ug.game.id,\n",
    "                            \"playtime\": pt,\n",
    "                            \"last_played\": ug.last_played,\n",
    "                        }\n",
    "                    )\n",
    "        data = pd.DataFrame(data)\n",
    "        time_80 = np.quantile(data.last_played.values, 0.8)\n",
    "        train = data[data[\"last_played\"] < time_80].copy()\n",
    "        val = data[data[\"last_played\"] >= time_80].copy()\n",
    "        train_user_ids = np.sort(np.unique(train.user_id.values))\n",
    "        num_users = len(train_user_ids)\n",
    "        userid2idx = {o: i for i, o in enumerate(train_user_ids)}\n",
    "        train[\"user_id\"] = train[\"user_id\"].apply(lambda x: userid2idx[x])\n",
    "        val[\"user_id\"] = val[\"user_id\"].apply(lambda x: userid2idx.get(x, -1))\n",
    "        val = val[val[\"user_id\"] >= 0].copy()\n",
    "        train_game_ids = np.sort(np.unique(train.game_id.values))\n",
    "        num_items = len(train_game_ids)\n",
    "        gameid2idx = {o: i for i, o in enumerate(train_game_ids)}\n",
    "        train[\"game_id\"] = train[\"game_id\"].apply(lambda x: gameid2idx[x])\n",
    "        val[\"game_id\"] = val[\"game_id\"].apply(lambda x: gameid2idx.get(x, -1))\n",
    "        val = val[val[\"game_id\"] >= 0].copy()\n",
    "\n",
    "        def valid_loss(model):\n",
    "            model.eval()\n",
    "            users = torch.LongTensor(val.user_id.values).cuda()\n",
    "            items = torch.LongTensor(val.game_id.values).cuda()\n",
    "            ratings = torch.FloatTensor(val.playtime.values).cuda()\n",
    "            y_hat = model(users, items)\n",
    "            loss = F.mse_loss(y_hat, ratings)\n",
    "            return loss.item()\n",
    "\n",
    "        def train_epocs(model, epochs=10, lr=0.01, wd=0.0):\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            for i in range(epochs):\n",
    "                model.train()\n",
    "                users = torch.LongTensor(train.user_id.values).cuda()\n",
    "                items = torch.LongTensor(train.game_id.values).cuda()\n",
    "                ratings = torch.FloatTensor(train.playtime.values).cuda()\n",
    "                y_hat = model(users, items)\n",
    "                loss = F.mse_loss(y_hat, ratings)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                testloss = valid_loss(model)\n",
    "                print(\"train loss %.3f valid loss %.3f\" % (loss.item(), testloss), end=\"\")\n",
    "                print(\"\\r\", end=\"\")\n",
    "\n",
    "        model = MF(num_users, num_items, emb_size=300).cuda()\n",
    "        train_epocs(model, epochs=300, lr=1, wd=1e-5)\n",
    "        train_epocs(model, epochs=300, lr=0.1, wd=1e-5)\n",
    "        train_epocs(model, epochs=300, lr=0.01, wd=1e-5)\n",
    "        train_epocs(model, epochs=300, lr=0.001, wd=1e-5)\n",
    "        print()\n",
    "        torch.save(model.state_dict(), user_data_dir / \"benchmark_model.dat\")\n",
    "        with (user_data_dir / \"benchmark_userid2idx.json\").open(\"w\") as data_file:\n",
    "            json.dump({int(k): int(v) for k, v in userid2idx.items()}, data_file)\n",
    "        with (user_data_dir / \"benchmark_gameid2idx.json\").open(\"w\") as data_file:\n",
    "            json.dump({int(k): int(v) for k, v in gameid2idx.items()}, data_file)\n",
    "        system.date_time_value = dt.datetime.now()\n",
    "        system.save()\n",
    "    with (user_data_dir / \"benchmark_userid2idx.json\").open() as data_file:\n",
    "        userid2idx = {int(k): v for k, v in json.load(data_file).items()}\n",
    "    with (user_data_dir / \"benchmark_gameid2idx.json\").open() as data_file:\n",
    "        gameid2idx = {int(k): v for k, v in json.load(data_file).items()}\n",
    "    num_users = len(userid2idx)\n",
    "    num_items = len(gameid2idx)\n",
    "    model = MF(num_users, num_items, emb_size=300).cuda()\n",
    "    model.load_state_dict(torch.load(user_data_dir / \"benchmark_model.dat\"))\n",
    "    model.eval()\n",
    "    if target_user.id in userid2idx:\n",
    "        users = torch.LongTensor([userid2idx[target_user.id]]).cuda()\n",
    "        games = list(gameid2idx.values())\n",
    "        items = torch.LongTensor(games).cuda()\n",
    "        result = model(users, items)\n",
    "        idx2gameid = {value: key for key, value in gameid2idx.items()}\n",
    "        result = {\n",
    "            idx2gameid[game_idx.item()]: score.item()\n",
    "            for score, game_idx in zip(result, items)\n",
    "        }\n",
    "        user_games = (\n",
    "            UserGame.select(UserGame.game, UserGame.last_played)\n",
    "            .where((UserGame.user == target_user) & (UserGame.playtime > 0))\n",
    "        )\n",
    "        last_played = np.quantile([ug.last_played for ug in user_games], 0.8)\n",
    "        played_user_games = user_games.where(UserGame.last_played < last_played)\n",
    "        played_games = [ug.game for ug in played_user_games]\n",
    "        games = {\n",
    "            Game.get_by_id(key): value\n",
    "            for key, value in sorted(\n",
    "                result.items(), key=lambda item: item[1], reverse=True\n",
    "            )\n",
    "        }\n",
    "        data = [\n",
    "            (game, score)\n",
    "            for game, score in games.items()\n",
    "            if game not in played_games\n",
    "            and get_game_stats(game).player_count > min_player_count\n",
    "            and game.rating >= 7\n",
    "        ]\n",
    "        if max_count == -1:\n",
    "            return dict(data)\n",
    "        else:\n",
    "            return dict(data[:max_count])\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def train_mobcf_for_user(users, try_count = 100):\n",
    "    best_accuracy = -1\n",
    "    best_min_player_count = 1\n",
    "    best_zscore_norm = False\n",
    "    file = Path(\"mobcf.csv\")\n",
    "    if file.exists():\n",
    "        df = pd.read_csv(file)\n",
    "        data = df.values.tolist()\n",
    "    else:\n",
    "        data = []\n",
    "    def check(min_player_count, zscore_norm):\n",
    "        sub_data = [el[:2] for el in data]\n",
    "        if [min_player_count, zscore_norm] in sub_data:\n",
    "            return True\n",
    "    for i in range(try_count):\n",
    "        try:\n",
    "            reset_benchmark_mobcf_for_user()\n",
    "            zscore_norm = random.choice([True, False])\n",
    "            min_player_count = random.randint(1, 50)\n",
    "            if check(min_player_count, zscore_norm):\n",
    "                print(\"already exist\")\n",
    "                continue\n",
    "            mobcf_accuracy = []\n",
    "            for user in users:\n",
    "                played_user_games = UserGame.select(\n",
    "                    UserGame.game, UserGame.last_played\n",
    "                ).where((UserGame.user == user) & (UserGame.playtime > 0))\n",
    "                last_played = np.quantile(\n",
    "                    [ug.last_played for ug in played_user_games], 0.8\n",
    "                )\n",
    "                input_user_games = played_user_games.where(\n",
    "                    UserGame.last_played < last_played\n",
    "                )\n",
    "                check_user_games = played_user_games.where(\n",
    "                    UserGame.last_played >= last_played\n",
    "                )\n",
    "                played_games = [ug.game for ug in input_user_games]\n",
    "                check_games = [ug.game for ug in check_user_games]\n",
    "                mbcf_result = get_benchmark_mobcf_for_user(\n",
    "                    user, -1, min_player_count, zscore_norm\n",
    "                )\n",
    "                mobcf_accuracy.append(check_result(list(mbcf_result.keys()), check_games))\n",
    "            current_accuracy = np.mean(mobcf_accuracy)\n",
    "            data.append([min_player_count, zscore_norm, current_accuracy])\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(file, index=False)\n",
    "            print(\"current\", current_accuracy, min_player_count, zscore_norm)\n",
    "            if best_accuracy < current_accuracy:\n",
    "                best_accuracy = current_accuracy\n",
    "                best_min_player_count = min_player_count\n",
    "                best_zscore_norm = zscore_norm\n",
    "            print(\"best\", best_accuracy, best_min_player_count, best_zscore_norm)\n",
    "        except ValueError:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_mobcf_for_user(users, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_benchmark_mobcf_for_user()\n",
    "# get_mobcf_for_user(User.get_by_id(76561198083927294))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hrs for game\n",
    "def merge_dicts(dicts: list):\n",
    "    result = {}\n",
    "    for d in dicts:\n",
    "        for v in d:\n",
    "            if v in result:\n",
    "                result[v] += d[v]\n",
    "            else:\n",
    "                result[v] = d[v]\n",
    "    result = {\n",
    "        key: value\n",
    "        for key, value in sorted(result.items(), key=lambda item: item[1], reverse=True)\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "def normalize_dict(dict_data: dict, coef: float = 1):\n",
    "    values = list(dict_data.values())\n",
    "    values = preprocessing.normalize([values])[0] * coef\n",
    "    return {k: v for k, v in zip(dict_data, values)}\n",
    "\n",
    "\n",
    "def get_benchmark_hrs_for_user(target_user, max_count=-1, cbr_coef = 0.27, mbcf_coef=0.95, mobcf_coef=0.62):\n",
    "    cbr_result = get_benchmark_cbr_for_user(target_user)\n",
    "    mbcf_result = get_benchmark_mbcf_for_user(target_user)\n",
    "    mobcf_result = get_benchmark_mobcf_for_user(target_user)\n",
    "    result = merge_dicts(\n",
    "        [\n",
    "            normalize_dict(cbr_result, cbr_coef),\n",
    "            normalize_dict(mbcf_result, mbcf_coef),\n",
    "            normalize_dict(mobcf_result, mobcf_coef),\n",
    "        ]\n",
    "    )\n",
    "    if max_count == -1:\n",
    "        return result\n",
    "    else:\n",
    "        return {k: v for k, v in list(result.items())[:max_count]}\n",
    "\n",
    "def train_hrs_for_user(users, try_count = 100):\n",
    "    best_accuracy = -1\n",
    "    best_cbr_coef = 0.01\n",
    "    best_mbcf_coef = 0.01\n",
    "    best_mobcf_coef = 0.01\n",
    "    file = Path(\"hrs.csv\")\n",
    "    if file.exists():\n",
    "        df = pd.read_csv(file)\n",
    "        data = df.values.tolist()\n",
    "    else:\n",
    "        data = []\n",
    "    def check(cbr_coef, mbcf_coef, mobcf_coef):\n",
    "        sub_data = [el[:3] for el in data]\n",
    "        if [cbr_coef, mbcf_coef, mobcf_coef] in sub_data:\n",
    "            return True\n",
    "    for i in range(try_count):\n",
    "        try:\n",
    "            cbr_coef= random.randint(1, 100) / 100.0\n",
    "            # cbr_coef= 0.88\n",
    "            mbcf_coef = random.randint(1, 100) / 100.0\n",
    "            # mbcf_coef = 0.73\n",
    "            mobcf_coef = random.randint(1, 100) / 100.0\n",
    "            # mobcf_coef = 0.03\n",
    "            if check(cbr_coef, mbcf_coef, mobcf_coef):\n",
    "                print(\"already exist\")\n",
    "                continue\n",
    "            hrs_accuracy = []\n",
    "            for user in users:\n",
    "                played_user_games = UserGame.select(\n",
    "                    UserGame.game, UserGame.last_played\n",
    "                ).where((UserGame.user == user) & (UserGame.playtime > 0))\n",
    "                last_played = np.quantile(\n",
    "                    [ug.last_played for ug in played_user_games], 0.8\n",
    "                )\n",
    "                input_user_games = played_user_games.where(\n",
    "                    UserGame.last_played < last_played\n",
    "                )\n",
    "                check_user_games = played_user_games.where(\n",
    "                    UserGame.last_played >= last_played\n",
    "                )\n",
    "                played_games = [ug.game for ug in input_user_games]\n",
    "                check_games = [ug.game for ug in check_user_games]\n",
    "                hrs_result = get_benchmark_hrs_for_user(\n",
    "                    user, -1, cbr_coef, mbcf_coef, mobcf_coef \n",
    "                )\n",
    "                hrs_accuracy.append(check_result(list(hrs_result.keys()), check_games))\n",
    "            current_accuracy = np.mean(hrs_accuracy)\n",
    "            data.append([cbr_coef, mbcf_coef, mobcf_coef, current_accuracy])\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(file, index=False)\n",
    "            print(\"current\", current_accuracy, cbr_coef, mbcf_coef, mobcf_coef)\n",
    "            if best_accuracy < current_accuracy:\n",
    "                best_accuracy = current_accuracy\n",
    "                best_cbr_coef = cbr_coef\n",
    "                best_mbcf_coef = mbcf_coef\n",
    "                best_mobcf_coef = mobcf_coef\n",
    "            print(\"best\", best_accuracy, best_cbr_coef, best_mbcf_coef, best_mobcf_coef)\n",
    "        except ValueError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_benchmark_cbr_for_user(users)\n",
    "# reset_benchmark_mbcf_for_user(users)\n",
    "# reset_benchmark_mobcf_for_user()\n",
    "# train_hrs_for_user(users, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.000 valid loss 0.97628574\n",
      "cbr accuracy: 0.14707883153261306\n",
      "mbcf accuracy: 0.2996937236433035\n",
      "mobcf accuracy: 0.08129713423831071\n",
      "hrs accuracy: 0.2954920429710346\n"
     ]
    }
   ],
   "source": [
    "# benchmark\n",
    "def check_result(result_games: list, check_games: list):\n",
    "    check_game_len = len(check_games)\n",
    "    return len(set(result_games[:len(check_games)]).intersection(check_games)) / check_game_len\n",
    "\n",
    "cbr_accuracy = []\n",
    "mbcf_accuracy = []\n",
    "mobcf_accuracy = []\n",
    "hrs_accuracy = []\n",
    "\n",
    "reset_benchmark_cbr_for_user(users)\n",
    "reset_benchmark_mbcf_for_user(users)\n",
    "reset_benchmark_mobcf_for_user()\n",
    "\n",
    "for user in users:\n",
    "    played_user_games = UserGame.select(UserGame.game, UserGame.last_played).where((UserGame.user == user) & (UserGame.playtime > 0))\n",
    "    last_played = np.quantile([ug.last_played for ug in played_user_games], 0.8)\n",
    "    input_user_games = played_user_games.where(UserGame.last_played < last_played)\n",
    "    check_user_games = played_user_games.where(UserGame.last_played >= last_played)\n",
    "    played_games = [ug.game for ug in input_user_games]\n",
    "    check_games = [ug.game for ug in check_user_games]\n",
    "    hrs_result = get_benchmark_hrs_for_user(user)\n",
    "    cbr_result = get_benchmark_cbr_for_user(user)\n",
    "    mbcf_result = get_benchmark_mbcf_for_user(user)\n",
    "    mobcf_result = get_benchmark_mobcf_for_user(user)\n",
    "    cbr_accuracy.append(check_result(list(cbr_result.keys()), check_games))\n",
    "    mbcf_accuracy.append(check_result(list(mbcf_result.keys()), check_games))\n",
    "    mobcf_accuracy.append(check_result(list(mobcf_result.keys()), check_games))\n",
    "    hrs_accuracy.append(check_result(list(hrs_result.keys()), check_games))\n",
    "print(\"cbr accuracy:\", np.mean(cbr_accuracy))\n",
    "print(\"mbcf accuracy:\", np.mean(mbcf_accuracy))\n",
    "print(\"mobcf accuracy:\", np.mean(mobcf_accuracy))\n",
    "print(\"hrs accuracy:\", np.mean(hrs_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('game-lists-site-LdBYsaDo-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dec19c2d43942376edf2e6e02c16686986e9d3bcd611ba70d2d35fdae1aa617c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
